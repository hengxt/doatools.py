{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coarrays, MUSIC, and the CramÃ©r-Rao bound\n",
    "\n",
    "This notebook contains scripts for analyzing the performance of SS-MUSIC and DA-MUSIC for various sparse linear arrays. You can use these scripts to produce figures similar to those in the following papers:\n",
    "\n",
    "```\n",
    "@article{wang_coarrays_2017,\n",
    "    title = {Coarrays, {MUSIC}, and the {Cram\\'{e}r}-{Rao} Bound},\n",
    "    volume = {65},\n",
    "    issn = {1053-587X},\n",
    "    doi = {10.1109/TSP.2016.2626255},\n",
    "    number = {4},\n",
    "    journal = {IEEE Trans. Signal Process.},\n",
    "    author = {Wang, M. and Nehorai, A.},\n",
    "    month = feb,\n",
    "    year = {2017},\n",
    "    pages = {933--946}\n",
    "}\n",
    "@inproceedings{wang_performance_2017,\n",
    "    title = {Performance analysis of coarray-based {MUSIC} and the {Cram\\'{e}r}-{Rao} bound},\n",
    "    doi = {10.1109/ICASSP.2017.7952719},\n",
    "    booktitle = {2017 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},\n",
    "    author = {Wang, M. and Zhang, Z. and Nehorai, A.},\n",
    "    month = mar,\n",
    "    year = {2017},\n",
    "    pages = {3061--3065}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdoatools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodel\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdoatools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mestimation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mestimation\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import doatools.model as model\n",
    "import doatools.estimation as estimation\n",
    "import doatools.performance as perf\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters\n",
    "wavelength = 1.0 # normalized\n",
    "d0 = wavelength / 2.0\n",
    "\n",
    "# Arrays\n",
    "arrays = [\n",
    "    model.CoPrimeArray(3, 5, d0, '2m', 'Co-prime Array'),\n",
    "    model.NestedArray(4, 6, d0, 'Nested Array'),\n",
    "    model.MinimumRedundancyLinearArray(10, d0, 'MRA')\n",
    "]\n",
    "n_arrays = len(arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical demonstration of the analytical MSE\n",
    "\n",
    "We compare the analytical MSE,\n",
    "\\begin{equation}\n",
    "\\mathrm{MSE}_{\\mathrm{an}} = \\frac{1}{K} \\sum_{k=1}^K \\epsilon(\\theta_k),\n",
    "\\end{equation}\n",
    "with the empirical MSE\n",
    "\\begin{equation}\n",
    "\\mathrm{MSE}_{\\mathrm{em}} = \\frac{1}{KL} \\sum_{l=1}^L\\sum_{k=1}^K(\\hat{\\theta}_k^{(l)} - \\theta_k^{(l)})^2,\n",
    "\\end{equation}\n",
    "where $\\epsilon(\\theta_k)$ is defined in (11), $\\theta_k^{(l)}$ is the $k$-th DOA in the $l$-th trial, and $\\theta_k^{(l)}$ is the corresponding estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "sources = model.FarField1DSourcePlacement(np.linspace(-np.pi*6/16, np.pi*5/16, 11))\n",
    "power_source = 1.0\n",
    "\n",
    "n_param_n_snapshots = 20\n",
    "n_param_snr = 20\n",
    "\n",
    "min_n_snapshots = 10\n",
    "max_n_snapshots = 1000\n",
    "min_snr = -20.0\n",
    "max_snr = 20.0\n",
    "\n",
    "params_n_snapshots = np.round(np.linspace(min_n_snapshots, max_n_snapshots, n_param_n_snapshots)).astype(np.int32)\n",
    "params_snr = np.linspace(min_snr, max_snr, n_param_snr)\n",
    "rv_modes = ['da', 'ss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set `n_repeats` to 100, which means each point in the final plots is averaged from 100 trials. The simulation will take 30-60 minutes depending on your CPU. The resulting plots will be noiser compared with Fig. 2 in the paper.\n",
    "\n",
    "You need to increase `n_repeats` to at least 5000 to obtain plots as clean as those in Fig. 2. The original scripts were written in MATLAB and utilized `parfor`, which were scalable on clusters. However, implementing `parfor` is not an easy task in Python, and running the full-scale simulations with a single CPU can be very time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Monte Carlo simulations.\n",
    "n_repeats = 100\n",
    "\n",
    "results_em = np.zeros((n_arrays, 2, n_param_n_snapshots, n_param_snr))\n",
    "results_an = np.zeros((n_arrays, 2, n_param_n_snapshots, n_param_snr))\n",
    "\n",
    "source_signal = model.ComplexStochasticSignal(sources.size, power_source)\n",
    "coarray_acm_builders = [estimation.CoarrayACMBuilder1D(arr) for arr in arrays]\n",
    "root_music = estimation.RootMUSIC1D(wavelength)\n",
    "\n",
    "# We have 4 varying parameters here. Pardon us for these for loops :)\n",
    "with tqdm(total=results_em.size) as pbar:\n",
    "    for dd, array in enumerate(arrays):\n",
    "        for ss, rv_mode in enumerate(rv_modes):\n",
    "            for ii, n_snapshots in enumerate(params_n_snapshots):\n",
    "                for jj, snr in enumerate(params_snr):\n",
    "                    power_noise = 10**(-snr/10) * np.min(power_source)\n",
    "                    noise_signal = model.ComplexStochasticSignal(array.size, power_noise)\n",
    "                    cur_mse = 0\n",
    "                    for rr in range(n_repeats):\n",
    "                        _, R = model.get_narrowband_snapshots(array, sources, wavelength, source_signal, noise_signal,\n",
    "                                                              n_snapshots, return_covariance=True)\n",
    "                        Rv = coarray_acm_builders[dd](R, rv_mode)\n",
    "                        _, estimates = root_music.estimate(Rv, sources.size, d0)\n",
    "                        cur_mse += np.sum((estimates.locations - sources.locations)**2)\n",
    "                    results_em[dd, ss, ii, jj] = cur_mse / (n_repeats * sources.size)\n",
    "                    C_an = perf.ecov_coarray_music_1d(array, sources, wavelength, power_source, power_noise, n_snapshots)\n",
    "                    results_an[dd, ss, ii, jj] = np.mean(np.diag(C_an))\n",
    "                    pbar.update(1)\n",
    "\n",
    "rel_errors = np.abs(results_an - results_em) / results_em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results.\n",
    "plt.figure(figsize=(7, 8))\n",
    "\n",
    "bounds = (params_snr[0], params_snr[-1], params_n_snapshots[-1], params_n_snapshots[0])\n",
    "for dd, array in enumerate(arrays):\n",
    "    # Left\n",
    "    ax = plt.subplot(n_arrays, 2, dd * 2 + 1)\n",
    "    plt.imshow(rel_errors[dd, 0, :, :], extent=bounds, aspect='auto',\n",
    "               cmap='gray_r', vmin=0.0, vmax=1.0)\n",
    "    ax.invert_yaxis()\n",
    "    plt.colorbar()\n",
    "    if dd == n_arrays - 1:\n",
    "        plt.xlabel('SNR (dB)')\n",
    "    plt.ylabel('Number of snapshots')\n",
    "    plt.title(arrays[dd].name + ' (DA-MUSIC)')\n",
    "    \n",
    "    # Right\n",
    "    ax = plt.subplot(n_arrays, 2, dd * 2 + 2);\n",
    "    plt.imshow(rel_errors[dd, 1, :, :], extent=bounds, aspect='auto',\n",
    "               cmap='gray_r', vmin=0.0, vmax=1.0)\n",
    "    ax.invert_yaxis()\n",
    "    plt.colorbar()\n",
    "    if dd == n_arrays - 1:\n",
    "        plt.xlabel('SNR (dB)')\n",
    "    plt.ylabel('Number of snapshots')\n",
    "    plt.title(arrays[dd].name + ' (SS-MUSIC)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of resolvability\n",
    "\n",
    "For illustration purpose, we analytically predict the resolvability of the two sources via the following simple criterion:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\epsilon(\\theta_1) + \\epsilon(\\theta_2) \n",
    "    \\underset{\\mathrm{Resolvable}}{\\overset{\\mathrm{Unresovalble}}{\\gtreqless}} \\Delta\\theta.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setups\n",
    "power_source = 1.0\n",
    "power_noise = 1.0 # SNR = 0 dB\n",
    "n_snapshots = 500\n",
    "n_repeats = 500\n",
    "\n",
    "theta_0 = np.pi/6\n",
    "delta_thetas = np.linspace(np.pi/60, np.pi/600, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions.\n",
    "def check_doa_correctness(actual, est, tolerance=np.Inf):\n",
    "    '''Checks if estimated doa is reasonably close to the actual ones.\n",
    "    \n",
    "    Input must be in ascending order within range of (-pi/2, pi/2).\n",
    "    \n",
    "    More precisely, suppose the true DOAs are x_1, x_2, ..., x_k, the estimated\n",
    "    DOAs must fall within the following regions:\n",
    "    (-pi/2, x_1 + (x_2 - x_1) / 2),\n",
    "    (x_1 + (x_2 - x_1) / 2, x_2 + (x_3 - x_2) / 2), ...\n",
    "    (x_k - (x_k - x_{k-1}) / 2, pi/2)\n",
    "    If tolerance is not inf, the estimated DOAs must also fall within the following\n",
    "    regions:\n",
    "    (x_1 - tolerance, x_1 + tolerance), ...\n",
    "    (x_k - tolerance, x_k + tolerance)\n",
    "    '''\n",
    "    n = actual.size\n",
    "    # Size mismatches.\n",
    "    if n != est.size:\n",
    "        return False\n",
    "    # Special case: one source only.\n",
    "    if n == 1:\n",
    "        return np.abs(actual[0] - est[0]) < tolerance\n",
    "    # General case\n",
    "    spaces = np.diff(actual)\n",
    "    max_deviations = np.minimum(0.5 * spaces, tolerance)\n",
    "    # First\n",
    "    if est[0] < max(-np.pi / 2, actual[0] - tolerance) or \\\n",
    "       est[0] > actual[0] + max_deviations[0]:\n",
    "        return False \n",
    "    # Last\n",
    "    if est[-1] > min(np.pi / 2, actual[-1] + tolerance) or \\\n",
    "       est[-1] < actual[-1] - max_deviations[-1]:\n",
    "        return False\n",
    "    # Middle parts\n",
    "    for i in range(1, n - 1):\n",
    "        if est[i] < actual[i] - max_deviations[i - 1] or \\\n",
    "           est[i] > actual[i] + max_deviations[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def check_resolution_ana(array, wavelength, doa1, doa2, power_source, power_noise, n_snapshots, l=1.0):\n",
    "    '''Checks if two sources are resolvable analytically with SS-MUSIC\n",
    "    (or DA-MUSIC) using the analytical asymptotic MSE we derived in (11)\n",
    "    after Theorem 1.\n",
    "    '''\n",
    "    # Ensure doa1 < doa2\n",
    "    if doa1 > doa2:\n",
    "        doa1, doa2 = doa2, doa1\n",
    "    sources = model.FarField1DSourcePlacement([doa1, doa2])\n",
    "    C = perf.ecov_coarray_music_1d(array, sources, wavelength, power_source, power_noise, n_snapshots)\n",
    "    # Apply the resolution criterion\n",
    "    return doa2 - doa1 > l * (np.sqrt(C[0, 0]) + np.sqrt(C[1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Monte Carlo simulations.\n",
    "resolution_success_rate = np.zeros((n_arrays, delta_thetas.size))\n",
    "resolution_threshold_ana = np.zeros((n_arrays,))\n",
    "\n",
    "coarray_acm_builders = [estimation.CoarrayACMBuilder1D(arr) for arr in arrays]\n",
    "root_music = estimation.RootMUSIC1D(wavelength)\n",
    "\n",
    "with tqdm(total=resolution_success_rate.size) as pbar:\n",
    "    for dd, array in enumerate(arrays):\n",
    "        source_signal = model.ComplexStochasticSignal(2, power_source)\n",
    "        noise_signal = model.ComplexStochasticSignal(array.size, power_noise)\n",
    "        # Marks unresolvable separations predicted by the analytical results.\n",
    "        unresolvable_flags = np.zeros((delta_thetas.size,))\n",
    "        for ii, delta_theta in enumerate(delta_thetas):\n",
    "            theta_1 = theta_0 - 0.5 * delta_theta\n",
    "            theta_2 = theta_0 + 0.5 * delta_theta\n",
    "            # Analytically check the minimal resolvable delta.\n",
    "            unresolvable_flags[ii] = not check_resolution_ana(array, wavelength, theta_1, theta_2,\n",
    "                                                              power_source, power_noise, n_snapshots)\n",
    "            # Collect the empirical success rate.\n",
    "            n_successes = 0\n",
    "            sources = model.FarField1DSourcePlacement([theta_1, theta_2])\n",
    "            for rr in range(n_repeats):                \n",
    "                _, R = model.get_narrowband_snapshots(array, sources, wavelength, source_signal, noise_signal,\n",
    "                                                      n_snapshots, return_covariance=True)\n",
    "                Rv = coarray_acm_builders[dd](R, 'ss')\n",
    "                _, estimates = root_music.estimate(Rv, 2, array.d0)\n",
    "                # Requires accurate resolution.\n",
    "                if check_doa_correctness(sources.locations, estimates.locations, 0.5 * delta_theta):\n",
    "                    n_successes += 1\n",
    "            resolution_success_rate[dd, ii] = n_successes / n_repeats\n",
    "            pbar.update(1)\n",
    "        min_delta_ana_idx = np.argmax(unresolvable_flags > 0)\n",
    "        if unresolvable_flags[min_delta_ana_idx] == 0:\n",
    "            resolution_threshold_ana[dd] = delta_thetas[0]\n",
    "        else:\n",
    "            resolution_threshold_ana[dd] = delta_thetas[min_delta_ana_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results.\n",
    "plt.figure()\n",
    "markers = ['+', 'o', 'd', '*']\n",
    "for dd, array in enumerate(arrays):\n",
    "    plt.plot(np.rad2deg(delta_thetas), resolution_success_rate[dd,:], '-' + markers[dd],\n",
    "                 label=array.name, color='C' + str(dd))\n",
    "    plt.gca().set_ylim((0, 1))\n",
    "    ana_threshold = np.rad2deg(resolution_threshold_ana[dd])\n",
    "    plt.plot([ana_threshold, ana_threshold], [0, 1], '--',  color='C' + str(dd),\n",
    "             label=array.name + ' Predicted')\n",
    "plt.xlabel('Separation (degree)')\n",
    "plt.ylabel('Rate of success')\n",
    "plt.title('Probability of resolution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency analysis\n",
    "\n",
    "We study the asymptotic statistical efficiency of DA-MUSIC and SS-MUSIC under different array geometries and parameter settings. We define their average efficiency as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\kappa = \\frac{\\mathrm{tr}(\\mathrm{CRB}_{\\boldsymbol{\\theta}})}{\\sum_{k=1}^K \\epsilon(\\theta_k)}.\n",
    "\\end{equation}\n",
    "\n",
    "For efficient estimators we expect $\\kappa = 1$, while for inefficient estimators we expect $0 \\leq \\kappa < 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "n_snapshots = 1 # normalized\n",
    "power_source = 1.0\n",
    "snrs = np.linspace(-10, 20, 30)\n",
    "n_snrs = snrs.size\n",
    "\n",
    "source_numbers = [1, 6, 12]\n",
    "n_experiments = len(source_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the statistical efficiency under difference SNRs.\n",
    "e1 = np.zeros((n_arrays, n_snrs, n_experiments))\n",
    "e2 = np.zeros((n_arrays, n_snrs, n_experiments))\n",
    "for kk, n_sources in enumerate(source_numbers):\n",
    "    sources = model.FarField1DSourcePlacement(\n",
    "        np.linspace(-np.pi / 3, np.pi / 3, n_sources))\n",
    "    for dd, array in enumerate(arrays):\n",
    "        for ii, snr in enumerate(snrs):\n",
    "            power_noise = power_source * 10**(-snr/10)\n",
    "            # Asymptotic covariance matrix\n",
    "            C = perf.ecov_coarray_music_1d(array, sources, wavelength, power_source,\n",
    "                                           power_noise, n_snapshots)\n",
    "            # CRB\n",
    "            B = perf.crb_stouc_farfield_1d(array, sources, wavelength, power_source,\n",
    "                                           power_noise, n_snapshots)\n",
    "            e1[dd, ii, kk] = np.sum(np.diag(C))\n",
    "            e2[dd, ii, kk] = np.sum(np.diag(B))\n",
    "            \n",
    "efficiency = e2 / e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(6, 10))\n",
    "for kk, n_sources in enumerate(source_numbers):\n",
    "    plt.subplot(n_experiments, 1, kk + 1)\n",
    "    markers = ['+', 'o', 'd', '*']\n",
    "    for dd, array in enumerate(arrays):\n",
    "        hp = plt.plot(snrs, efficiency[dd, :, kk], '-' + markers[dd], label=array.name)\n",
    "    plt.xlabel('SNR')\n",
    "    plt.ylabel('Average efficiency')\n",
    "    plt.axis([-10, 20, 0, 1])\n",
    "    plt.title('K = {0:d}'.format(n_sources))\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
